"""
Created on Sun Mar 29 21:48:36 2020

Test library:https://www.kaggle.com/thedownhill/art-images-drawings-painting-sculpture-engraving
Test environment: notebook cpu i5-8250U1.60GHz ram 7.9GB GPU NVIDA GeForce MX150
Models: vgg16 batch_size->12 pixel[128,128] 

@author: sung
"""
import os

import torch
import torch.nn as nn
import torch.utils.data as Data
import torchvision
from torchvision import datasets, models, transforms
from torch.autograd import Variable
import time

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
data_dir = "dataset_updated" #The name of the profile to use


LR = 1e-6 #learning_rate


data_transform = {x:transforms.Compose(
    [transforms.Scale([128,128]),  #pixel->128*128
    transforms.ToTensor()])
    for x in["train", "valid"]}

image_datasets = {x:datasets.ImageFolder(
    root = os.path.join(data_dir,x),
    transform = data_transform[x])
    for x in ["train","valid"]}

dataloader = {x:torch.utils.data.DataLoader(
    dataset = image_datasets[x],
    batch_size = 12,   #Mini-batch Gradient Descent
    shuffle = True)
    for x in ["train","valid"]}

model = models.vgg16(pretrained=True)

for param in model.parameters(): 
    param.requires_grad = False    # Freeze model parameters

model.classifier = torch.nn.Sequential(nn.Linear(25088, 4096),
                                       nn.ReLU(),
                                       nn.Dropout(p=0.5),
                                       nn.Linear(4096, 4096),
                                       nn.ReLU(),
                                       nn.Dropout(p=0.5),
                                       nn.Linear(4096, 5)
                                       )
model.to(device)  # Tensor on GPU

cost = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.classifier.parameters())
loss_func = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.classifier.parameters(), lr = LR) 

time_open = time.time()
epoch_n = 5

for epoch in range(epoch_n):
    print("Epoch {}/{}".format(epoch,epoch_n-1))
    print("-"*10)
    for phase in["train","valid"]:
        if phase == "train":
            print("Training...")
            model.train(True)
        else:
            print("Validing...")
            model.train(False)
        
        running_loss = 0.0
        running_corrects = 0
        
        for step, (x, y) in enumerate(dataloader[phase],1):
    
            b_x = x.cuda()    # Tensor on GPU
            b_y = y.cuda()    # Tensor on GPU
            b_x = Variable(b_x,requires_grad=True)
            b_y = Variable(b_y)
            output = model(b_x)
            
            _, pred = torch.max(output.data,1)
            optimizer.zero_grad()
            
            loss = loss_func(output, b_y)
            
            if phase == "train":
                loss.backward()
                optimizer.step()
                
            running_loss += loss.item()
            running_corrects += torch.sum(pred == b_y.data)
            
            if step %10 ==0 and phase == "train":
                print("Batch{}, Train Loss:{:.4f},Train ACC:{:.4f}".format(step, running_loss/step, 100*running_corrects/(16*step)))
                
        epoch_loss = running_loss*16/len(image_datasets[phase])
        epoch_acc = 100*running_corrects/len(image_datasets[phase])
        
        print("{} Loss:{:.4f} ACC:{:.4f}%".format(phase, epoch_loss, epoch_acc))
        
time_end = time.time() - time_open
print(time_end)
