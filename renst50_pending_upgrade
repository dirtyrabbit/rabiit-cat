"""
Created on Sun Mar 29 21:48:36 2020

Test library:https://www.kaggle.com/thedownhill/art-images-drawings-painting-sculpture-engraving
Test environment: notebook cpu i5-8250U1.60GHz ram 7.9GB GPU NVIDA GeForce MX150
@author: User
"""
import os

import torch
import torch.nn as nn
import torch.utils.data as Data
import torch.optim as optim
import torchvision
from torchvision import datasets, models, transforms
from torch.autograd import Variable
import time

import numpy as np
import matplotlib.pyplot as plt


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
data_dir = "dataset_updated" 

LR = 1e-6 #learning_rate

data_transform = {x:transforms.Compose(
    [transforms.RandomResizedCrop(size=256, scale=(0.8,1.0)),  
    transforms.RandomRotation(degrees=15),
    transforms.RandomHorizontalFlip(),
    transforms.CenterCrop(size=224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])for x in["train", "valid"]}

image_datasets = {x:datasets.ImageFolder(
    root = os.path.join(data_dir,x),
    transform = data_transform[x])
    for x in ["train","valid"]}

dataloader = {x:torch.utils.data.DataLoader(
    dataset = image_datasets[x],
    batch_size = 16,
    shuffle = True)
    for x in ["train","valid"]
    }

resnet50 = models.resnet50(pretrained=True)

for param in resnet50.parameters(): 
    param.requires_grad = False    # Freeze model parameters

fc_inputs = resnet50.fc.in_features
resnet50.fc = nn.Sequential(
    nn.Linear(fc_inputs, 256),
    nn.ReLU(),
    nn.Dropout(0.4),
    nn.Linear(256, 5),
    nn.LogSoftmax(dim=1)
)
resnet50.to(device)  # Tensor on GPU

loss_nll = nn.NLLLoss()


loss_CE = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet50.parameters(), lr = LR) 

time_open = time.time()
epoch_n = 5

def train_and_valid(resnet50, loss_function, optimizer, epoch_n = 25):#epoch_n=5
    
    history = []
    best_acc =0.0
    best_epoch = 0
    
    for epoch in range(epoch_n):
        print("Epoch {}/{}".format(epoch,epoch_n-1))
        print("-"*10)
        for phase in["train","valid"]:
            if phase == "train":
                print("Training...")
                resnet50.train(True)                
            else:
                print("Validing...")
                resnet50.train(False)
                # with torch.no_grad(): #在autograd里不跟踪这次 weight - grad的运算。
                #     resnet50.eval() #切换到测试模式
                
            train_loss = 0.0
            train_acc = 0.0
            
            running_loss = 0.0
            running_corrects = 0
            

            for step, (x, y) in enumerate(dataloader[phase],1): 
                
                inputs, labels = x.cuda(), y.cuda()    # Tensor on GPU
                if phase == "train":
                    inputs = Variable(inputs,requires_grad=True)
                else:
                    inputs = Variable(inputs)  
                labels = Variable(labels)    
                
                optimizer.zero_grad()
                outputs = resnet50(inputs)
                loss = loss_function(outputs, labels)
                if phase == "train":
                    loss.backward() # Back Propagation
                    optimizer.step() # Gardient Descent
                
                train_loss += loss.item() * inputs.size(0)

                ret, pred = torch.max(outputs.data, 1)#

                running_loss += loss.item()
                
                running_corrects += torch.sum(pred == labels.data)

                
                correct_counts = pred.eq(labels.data.view_as(pred))#
                acc = torch.mean(correct_counts.type(torch.FloatTensor))#
                train_acc += acc.item() * inputs.size(0)#
                    
                               
                if step %10 ==0 and phase == "train":
                    print("Batch{}, Train Loss:{:.4f},Train ACC:{:.4f}".format(step, running_loss/step, 100*running_corrects/(16*step)))
             #------------------------------------       
            avg_train_loss = 0.0
            avg_train_acc = 0.0          
                        
            epoch_loss = running_loss*16/len(image_datasets[phase])
            epoch_acc = 100*running_corrects/len(image_datasets[phase])
            
            
            if best_acc < epoch_acc:
                best_acc = epoch_acc
                best_epoch = epoch + 1
           
            history.append([avg_train_loss, epoch_loss, avg_train_acc, epoch_acc])
            
            epoch_end = time.time()
            print("-"*10)
            print("Epoch: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \n\t\tValidation: Loss: {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s".format(
            epoch+1, running_loss/step, 100*running_corrects/(16*step), epoch_loss, epoch_acc, epoch_end-time_open
            ))
            print("Best Accuracy for validation : {:.4f} at epoch {:03d}".format(best_acc, best_epoch))
 
            torch.save(resnet50, 'python'+data_dir+'_model_'+str(epoch+1)+'.pt')
            #-----------------------------------------
    return resnet50, history

# time_end = time.time() - time_open
# print(time_end)
    
num_epochs = 5
trained_model, history = train_and_valid(resnet50, loss_CE, optimizer, num_epochs)
torch.save(history, 'python' +data_dir+'_history.pt')
 
history = np.array(history)
plt.plot(history[:, 0:2])
plt.legend(['Tr Loss', 'Val Loss'])
plt.xlabel('Epoch Number')
plt.ylabel('Loss')
plt.ylim(0, 1)
plt.savefig(data_dir+'_loss_curve.png')
plt.show()
 
plt.plot(history[:, 2:4])
plt.legend(['Tr Accuracy', 'Val Accuracy'])
plt.xlabel('Epoch Number')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.savefig(data_dir+'_accuracy_curve.png')
plt.show()
